# -*- coding: utf-8 -*-
"""CVd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZbBktiCplHl3Hgk10nXbExKCsVTFyRv2
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Read the dataset
df = pd.read_csv("Heart_Disease_Prediction.csv")

# Drop rows with missing values
df = df.dropna()

# Encode categorical features
le = LabelEncoder()
df["Heart Disease"] = le.fit_transform(df["Heart Disease"])

# Separate features and target variables
X = df.drop("Heart Disease", axis=1)
y = df["Heart Disease"]

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Random Forest classifier with more estimators
clf = RandomForestClassifier(n_estimators=200, random_state=42)
clf.fit(X_train, y_train)

# Print the feature importance scores
importances = clf.feature_importances_
indices = np.argsort(importances)[::-1]

# Visualize the feature importance
plt.figure(figsize=(10, 7))
sns.barplot(x=importances[indices], y=X_train.columns[indices])
plt.title("Feature Importance")
plt.xlabel("Score")
plt.ylabel("Features")
plt.show()



plt.figure(figsize=(15, 15))
sns.heatmap(df.corr(), annot=True)
plt.show()

# Make predictions on the testing data
y_pred = clf.predict(X_test)

# Evaluate the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Print the classification report
print(classification_report(y_test, y_pred))

# Print the confusion matrix
print(confusion_matrix(y_test, y_pred))